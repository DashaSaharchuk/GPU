#include <cuda.h>
#include <stdio.h>
#include <stdlib.h>

//int N = 32;
//int size_block_x = 32, size_block_y = 32;

__global__ void transpose_sh_mem(float *sourse, float *result) {
    __shared__ float buffer[32][32];
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    int j = threadIdx.y + blockIdx.y * blockDim.y;
    int N = blockDim.x * gridDim.x;
    buffer[threadIdx.y][threadIdx.x] = sourse[i + j * N];
    __syncthreads();
    i = threadIdx.x + blockIdx.y * blockDim.x;
    j = threadIdx.y + blockIdx.x * blockDim.y;
    result[i + j * N] = buffer[threadIdx.x][threadIdx.y];
}

__global__ void transpose_sh_mem2(float *sourse, float *result) {
    __shared__ float buffer[32][33];
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    int j = threadIdx.y + blockIdx.y * blockDim.y;
    int N = blockDim.x * gridDim.x;
    buffer[threadIdx.y][threadIdx.x] = sourse[i + j * N];
    __syncthreads();
    i = threadIdx.x + blockIdx.y * blockDim.x;
    j = threadIdx.y + blockIdx.x * blockDim.y;
    result[i + j * N] = buffer[threadIdx.x][threadIdx.y];
}

__global__ void common_transpose(float *sourse, float *result) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    int j = threadIdx.y + blockIdx.y * blockDim.y;
    int N = blockDim.x * gridDim.x;
    result[i * N + j] = sourse[j * N + i];
}
int main(int argc, char* argv[]) {
    srand(time(NULL));
    int N = atoi(argv[1]);
    int dim_of_threads = atoi(argv[2]);
    float *a, *b;
    float *array = (float*) malloc(N * N * sizeof(float));
    float *result = (float*) malloc(N * N * sizeof(float));
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            array[i * N + j] = rand() % 100;
        }
    }
    printf("Source matrix:");
    //print_matrix(array);
    cudaMalloc(&a, N * N * sizeof(float));
    cudaMalloc(&b, N * N * sizeof(float));
    cudaMemcpy(a, array, N * N * sizeof(float), cudaMemcpyHostToDevice);
    common_transpose <<< dim3(N / dim_of_threads, N / dim_of_threads), dim3(dim_of_threads, dim_of_threads) >>> (a, b);
    cudaDeviceSynchronize();
    memset(result, 0, N * N * sizeof(float));
    cudaMemcpy(result, b, N * N * sizeof(float), cudaMemcpyDeviceToHost);
    printf("Common transpose:");
    //print_matrix(result);
    transpose_sh_mem <<< dim3(N / dim_of_threads, N / dim_of_threads), dim3(dim_of_threads, dim_of_threads) >>> (a, b);
    cudaDeviceSynchronize();
    memset(result, 0, N * N * sizeof(float));
    cudaMemcpy(result, b, N * N * sizeof(float), cudaMemcpyDeviceToHost);
    printf("Shared memory transpose:");
    //print_matrix(result);
    transpose_sh_mem2 <<< dim3(N / dim_of_threads, N / dim_of_threads), dim3(dim_of_threads, dim_of_threads) >>> (a, b);
    cudaDeviceSynchronize();
    memset(result, 0, N * N * sizeof(float));
    cudaMemcpy(result, b, N * N * sizeof(float), cudaMemcpyDeviceToHost);
    printf("Non conflict sh_mem transpose:");
    //print_matrix(result);
}
